{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TopicGPT_Python package\n",
    "\n",
    "`topicgpt_python` consists of five modules in total: \n",
    "- `generate_topic_lvl1` generates high-level and generalizable topics. \n",
    "- `generate_topic_lvl2` generates low-level and specific topics to each high-level topic.\n",
    "- `refine_topics` refines the generated topics by merging similar topics and removing irrelevant topics.\n",
    "- `assign_topics` assigns the generated topics to the input text, along with a quote that supports the assignment.\n",
    "- `correct_topics` corrects the generated topics by reprompting the model so that the topic assignment is grounded in the topic list. \n",
    "\n",
    "![topicgpt_python](assets/img/pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "1. Make a new Python 3.9+ environment using virtualenv or conda. \n",
    "2. Install the required packages: `pip install --upgrade topicgpt_python`.\n",
    "- Our package supports OpenAI API, Google Cloud Vertex AI API, and vLLM inference. vLLM requires GPUs to run. \n",
    "- Please refer to https://openai.com/pricing/ for OpenAI API pricing or to https://cloud.google.com/vertex-ai/pricing for Vertex API pricing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2333545508.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    export OPENAI_API_KEY={your_openai_api_key}\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Run in shell\n",
    "!pip install --upgrade topicgpt_python\n",
    "export OPENAI_API_KEY={your_openai_api_key}\n",
    "\n",
    "# Needed only for the Vertex AI deployment\n",
    "export VERTEX_PROJECT={your_vertex_project}   # e.g. my-project\n",
    "export VERTEX_LOCATION={your_vertex_location} # e.g. us-central1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "1. First, define the necessary file paths for I/O operations in `config.yml`. \n",
    "2. Then, import the necessary modules and functions from `topicgpt_python`.\n",
    "3. Store your data in `data/input` and modify the `data_sample` path in `config.yml`. \n",
    "\n",
    "- Prepare your `.jsonl` data file in the following format:\n",
    "    ```\n",
    "    {\n",
    "        \"id\": \"IDs (optional)\",\n",
    "        \"text\": \"Documents\",\n",
    "        \"label\": \"Ground-truth labels (optional)\"\n",
    "    }\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topicgpt_python import *\n",
    "import yaml\n",
    "\n",
    "with open(\"config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Generation \n",
    "Generate high-level topics using `generate_topic_lvl1`. \n",
    "- Define the api type and model. \n",
    "- Define your seed topics in `prompt/seed_1.md`.\n",
    "- (Optional) Modify few-shot examples in `prompt/generation_1.txt`.\n",
    "- Expect the generated topics in `data/output/{data_name}/generation_1.md` and `data/output/{data_name}/generation_1.jsonl`.\n",
    "- Right now, early stopping is set to 100, meaning that if no new topic has been generated in the last 100 iterations, the generation process will stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Initializing topic generation...\n",
      "Model: gpt-4o\n",
      "Data file: data/input/sample.jsonl\n",
      "Prompt file: prompt/generation_1.txt\n",
      "Seed file: prompt/seed_1.md\n",
      "Output file: data/output/sample/generation_1.jsonl\n",
      "Topic file: data/output/sample/generation_1.md\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:03<00:13,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 610 ~$0.0030499999999999998\n",
      "Response token usage: 18 ~$0.00027\n",
      "Topics: [1] Environment: Involves the conservation and management of natural resources and ecosystems.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:04<00:06,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 1271 ~$0.0063549999999999995\n",
      "Response token usage: 24 ~$0.00036\n",
      "Topics: [1] Environment: Mentions the use of land and natural resources, including hydropower generation and land management.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:06<00:03,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 823 ~$0.004115\n",
      "Response token usage: 17 ~$0.000255\n",
      "Topics: [1] Environment: Mentions the protection and management of natural habitats and ecosystems.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:07<00:01,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 632 ~$0.0031599999999999996\n",
      "Response token usage: 24 ~$0.00036\n",
      "Topics: [1] Transportation: Involves the development and management of systems and infrastructure for the movement of people and goods.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:10<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 571 ~$0.002855\n",
      "Response token usage: 28 ~$0.00042\n",
      "Topics: [1] Transportation: Relates to the systems and methods for moving people or goods from one place to another, including regulations and licensing.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<topicgpt_python.utils.TopicTree at 0x34b3364c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_topic_lvl1(\n",
    "    \"openai\",\n",
    "    \"gpt-4o\",\n",
    "    config[\"data_sample\"],\n",
    "    config[\"generation\"][\"prompt\"],\n",
    "    config[\"generation\"][\"seed\"],\n",
    "    config[\"generation\"][\"output\"],\n",
    "    config[\"generation\"][\"topic_output\"],\n",
    "    verbose=config[\"verbose\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Refinement\n",
    "If topics are generated by a weaker model, there sometimes exist irrelevant or redundant topics. This module: \n",
    "- Merges similar topics.\n",
    "- Removes overly specific or redundant topics that occur < 1% of the time (you can skip this by setting `remove` to False in `config.yml`).\n",
    "- Expect the refined topics in `data/output/{data_name}/refinement_1.md` and `data/output/{data_name}/refinement_1.jsonl`. If nothing happens, it means that the topic list is coherent.\n",
    "- If you're unsatisfied with the refined topics, call the function again with the refined topic file and refined topic file from the previous iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Initializing topic refinement...\n",
      "Model: gpt-4o\n",
      "Input data file: data/output/sample/generation_1.jsonl\n",
      "Prompt file: prompt/refinement.txt\n",
      "Output file: data/output/sample/refinement.md\n",
      "Topic file: data/output/sample/generation_1.md\n",
      "-------------------\n",
      "No topic pairs to be merged.\n",
      "No topics removed.\n",
      "Node('/Topics', count=1, desc='Root topic', lvl=0)\n",
      "├── Node('/Topics/Environment', count=3, desc='Involves the conservation and management of natural resources and ecosystems.', lvl=1)\n",
      "└── Node('/Topics/Transportation', count=2, desc='Involves the development and management of systems and infrastructure for the movement of people and goods.', lvl=1)\n"
     ]
    }
   ],
   "source": [
    "# Optional: Refine topics if needed\n",
    "if config[\"refining_topics\"]:\n",
    "    refine_topics(\n",
    "        \"openai\",\n",
    "        \"gpt-4o\",\n",
    "        config[\"refinement\"][\"prompt\"],\n",
    "        config[\"generation\"][\"output\"],\n",
    "        config[\"generation\"][\"topic_output\"],\n",
    "        config[\"refinement\"][\"topic_output\"],\n",
    "        config[\"refinement\"][\"output\"],\n",
    "        verbose=config[\"verbose\"],\n",
    "        remove=config[\"refinement\"][\"remove\"],\n",
    "        mapping_file=config[\"refinement\"][\"mapping_file\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtopic Generation \n",
    "Generate subtopics using `generate_topic_lvl2`.\n",
    "- This function iterates over each high-level topic and generates subtopics based on a few example documents associated with the high-level topic.\n",
    "- Expect the generated topics in `data/output/{data_name}/generation_2.md` and `data/output/{data_name}/generation_2.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Initializing topic generation (lvl 2)...\n",
      "Model: gpt-4o\n",
      "Data file: data/output/sample/generation_1.jsonl\n",
      "Prompt file: prompt/generation_2.txt\n",
      "Seed file: data/output/sample/generation_1.md\n",
      "Output file: data/output/sample/generation_2.jsonl\n",
      "Topic file: data/output/sample/generation_2.md\n",
      "-------------------\n",
      "Number of remaining documents for prompting: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current topic: [1] Environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtopics: [1] Environment\n",
      "   [2] Conservation (Document: 1): Focuses on the management and protection of natural areas to maintain their ecological integrity, such as roadless areas in national forests.\n",
      "   [2] Indigenous Rights and Compensation (Document: 2): Pertains to the rights and compensation of indigenous tribes for the use of their lands, particularly in relation to resource development and energy projects.\n",
      "   [2] Marine Habitat Protection (Document: 3): Involves the protection and management of marine ecosystems, particularly concerning the conversion of decommissioned oil and gas platforms into artificial reefs.\n",
      "Conservation (Count: 0): Focuses on the management and protection of natural areas to maintain their ecological integrity, such as roadless areas in national forests.\n",
      "Indigenous Rights and Compensation (Count: 0): Pertains to the rights and compensation of indigenous tribes for the use of their lands, particularly in relation to resource development and energy projects.\n",
      "Marine Habitat Protection (Count: 0): Involves the protection and management of marine ecosystems, particularly concerning the conversion of decommissioned oil and gas platforms into artificial reefs.\n",
      "--------------------------------------------------\n",
      "Current topic: [1] Transportation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtopics: [1] Transportation\n",
      "    [2] Aerotropolis Development (Document: 1): Involves planning and developing transportation systems centered around major airports.\n",
      "    [2] Licensing and Identification (Document: 2): Concerns regulations and requirements for issuing driver's licenses and identification documents.\n",
      "Aerotropolis Development (Count: 0): Involves planning and developing transportation systems centered around major airports.\n",
      "Licensing and Identification (Count: 0): Concerns regulations and requirements for issuing driver's licenses and identification documents.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Optional: Generate subtopics\n",
    "if config[\"generate_subtopics\"]:\n",
    "    generate_topic_lvl2(\n",
    "        \"openai\",\n",
    "        \"gpt-4o\",\n",
    "        config[\"generation\"][\"topic_output\"],\n",
    "        config[\"generation\"][\"output\"],\n",
    "        config[\"generation_2\"][\"prompt\"],\n",
    "        config[\"generation_2\"][\"output\"],\n",
    "        config[\"generation_2\"][\"topic_output\"],\n",
    "        verbose=config[\"verbose\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Assignment\n",
    "Assign the generated topics to the input text using `assign_topics`. Each assignment is supported by a quote from the input text.\n",
    "- Expect the assigned topics in `data/output/{data_name}/assignment.jsonl`. \n",
    "- The model used here is often a weaker model to save cost, so the topics may not be grounded in the topic list. To correct this, use the `correct_topics` module. If there are still errors/hallucinations, run the `correct_topics` module again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Initializing topic assignment...\n",
      "Model: gpt-4o-mini\n",
      "Data file: data/input/sample.jsonl\n",
      "Prompt file: prompt/assignment.txt\n",
      "Output file: data/output/sample/assignment.jsonl\n",
      "Topic file: data/output/sample/generation_1.md\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:02<00:08,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 509 ~$0.002545\n",
      "Response token usage: 49 ~$0.000735\n",
      "Response: [1] Environment: The document discusses the management of roadless areas within the National Forest System, which involves conservation efforts to maintain their natural state. (\"...directs the Secretary of Agriculture to manage such Areas to maintain their roadless character.\")\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:06<00:09,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 1165 ~$0.005825\n",
      "Response token usage: 208 ~$0.00312\n",
      "Response: [1] Environment: The document discusses the compensation for the Spokane Tribe of Indians for the use of their land for hydropower generation, which relates to the management of natural resources and ecosystems. The mention of land being held in trust and the federal trust responsibility indicates a focus on environmental and resource management. \n",
      "\n",
      "Supporting quote: \"the purpose of this Act is to compensate the Spokane Tribe of Indians of the Spokane Reservation, Washington State for the use of its land for hydropower generation by the Grand Coulee Dam.\" \n",
      "\n",
      "[1] Transportation: The document also touches on the management of land and resources related to the Grand Coulee Dam, which is a significant infrastructure project for the movement of hydropower. The mention of the Bonneville Power Administration, which markets power produced at the dam, indicates a connection to transportation of energy resources.\n",
      "\n",
      "Supporting quote: \"Directs the Administrator of the Bonneville Power Administration (or the head of a successor entity that markets power produced at the Grand Coulee Dam) to pay to the Tribe...\"\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:08<00:05,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 717 ~$0.0035849999999999996\n",
      "Response token usage: 80 ~$0.0012000000000000001\n",
      "Response: [1] Environment: The document discusses the assessment and protection of marine habitats related to offshore oil and gas platforms, which directly relates to the conservation and management of natural resources and ecosystems. \n",
      "\n",
      "Supporting quote: \"Directs the Secretary of the Interior to assess each offshore oil and gas platform in the Gulf of Mexico that is no longer useful for operations, and has become critical for a marine fisheries habitat...\"\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:09<00:02,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 526 ~$0.00263\n",
      "Response token usage: 51 ~$0.000765\n",
      "Response: [1] Transportation: The document discusses the establishment of an aerotropolis grant program aimed at developing transportation systems that enhance connectivity and efficiency. (\"...establish an aerotropolis grant program to assist in the development of aerotropolis transportation systems...\")\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:10<00:00,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 460 ~$0.0023\n",
      "Response token usage: 62 ~$0.00093\n",
      "Response: [1] Transportation: The document discusses the issuance of driver's licenses and identification documents, which relates to the management of systems for the movement of people. (\"...prohibit a state from issuing a driver's license or identification document to a person unless the state has complied with certain citizenship or lawful immigration status verification requirements.\")\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assignment\n",
    "assign_topics(\n",
    "    \"openai\",\n",
    "    \"gpt-4o-mini\",\n",
    "    config[\"data_sample\"],\n",
    "    config[\"assignment\"][\"prompt\"],\n",
    "    config[\"assignment\"][\"output\"],\n",
    "    config[\"generation\"][\n",
    "        \"topic_output\"\n",
    "    ],  # TODO: change to generation_2 if you have subtopics, or config['refinement']['topic_output'] if you refined topics\n",
    "    verbose=config[\"verbose\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Initializing topic correction...\n",
      "Model: gpt-4o-mini\n",
      "Data file: data/output/sample/assignment.jsonl\n",
      "Prompt file: prompt/correction.txt\n",
      "Output file: data/output/sample/assignment_corrected.jsonl\n",
      "Topic file: data/output/sample/generation_1.md\n",
      "-------------------\n",
      "Number of errors: 0\n",
      "Number of hallucinated topics: 0\n",
      "All topics are correct.\n"
     ]
    }
   ],
   "source": [
    "# Correction\n",
    "correct_topics(\n",
    "    \"openai\",\n",
    "    \"gpt-4o-mini\",\n",
    "    config[\"assignment\"][\"output\"],\n",
    "    config[\"correction\"][\"prompt\"],\n",
    "    config[\"generation\"][\n",
    "        \"topic_output\"\n",
    "    ],  # TODO: change to generation_2 if you have subtopics, or config['refinement']['topic_output'] if you refined topics\n",
    "    config[\"correction\"][\"output\"],\n",
    "    verbose=config[\"verbose\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topicgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
